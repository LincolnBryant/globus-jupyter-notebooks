{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to SDK Exercises\n",
    "\n",
    "## Setup\n",
    "\n",
    "Setup an instance of `TransferClient` to use in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # for python 2\n",
    "import globus_sdk\n",
    "\n",
    "tutorial_endpoint_1 = \"ddb59aef-6d04-11e5-ba46-22000b92c6ec\"      # endpoint \"Globus Tutorial Endpoint 1\"\n",
    "tutorial_endpoint_2 = \"ddb59af0-6d04-11e5-ba46-22000b92c6ec\"      # endpoint \"Globus Tutorial Endpoint 2\"\n",
    "\n",
    "transfer_token = None # copy token from SDK notebook, or get one from https://tokens.globus.org\n",
    "\n",
    "tc = globus_sdk.TransferClient(token=transfer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the endpoint id for XSEDE Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"XSEDE Comet\"\n",
    "eps = tc.endpoint_search(endpoint_name, fields=\"id,display_name\")\n",
    "endpoint_id = None\n",
    "for ep in eps:\n",
    "    if ep[\"display_name\"] == endpoint_name:\n",
    "        endpoint_id = ep[\"id\"]\n",
    "        break\n",
    "\n",
    "if endpoint_id is None:\n",
    "    print(\"Error: endpoint with name '{}' not found\")\n",
    "else:\n",
    "    print(\"Id of endpoint with name'{}': {}\".format(endpoint_name, endpoint_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set all the metadata fields on your shared endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy id from SDK notebook output,\n",
    "# or find on Web app starting at https://www.globus.org/app/endpoints?scope=shared-by-me\n",
    "shared_endpoint_id = \"d6905986-0701-11e6-a738-22000bf2d559\"\n",
    "ep_update = {\n",
    "    \"DATA_TYPE\": \"endpoint\",\n",
    "    \"description\": \"Better description for my share created from globus-jupyter-notebook\",\n",
    "    \"keywords\": \"GlobusWorld 2016\",\n",
    "    \"organization\": \"GlobusWorld Example Org\",\n",
    "    \"department\": \"Example Dept\",\n",
    "    \"contact_email\": \"youraddress@example.org\",\n",
    "    \"info_link\": \"https://www.example.org/globusendpoints/\"\n",
    "}\n",
    "update_result = tc.update_endpoint(shared_endpoint_id, ep_update)\n",
    "print(\"{}: {}\".format(update_result[\"code\"], update_result[\"message\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify mkdir so that an existing directory does not raise an exception, but all other errors do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endpoint_id = tutorial_endpoint_1\n",
    "nonexistent_endpoint_id = \"28ff8e5b-23f4-4572-b498-9dcdc792999a\"\n",
    "endpoint_path = \"/~/tutorial_dir\"\n",
    "try:\n",
    "    # will result in Exists error if the cell is executed more than once\n",
    "    mkdir_result = tc.operation_mkdir(endpoint_id, path=endpoint_path)\n",
    "    \n",
    "    # Trigger an EndpointNotFound error, which should be raised in the else clause below\n",
    "    #mkdir_result = tc.operation_mkdir(nonexistent_endpoint_id, path=endpoint_path)\n",
    "    \n",
    "    print(mkdir_result[\"message\"])\n",
    "except globus_sdk.GlobusAPIError as ex:\n",
    "    # ignore exists error, re-raise anything else\n",
    "    # Note that in a future API revision, this error will change to be just \"Exists\", but we will make\n",
    "    # a namespace change so existing clients will not break.\n",
    "    if ex.code == \"ExternalError.MkdirFailed.Exists\":\n",
    "        print(\"Directory already exists\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set access manager role on your shared endpoint, and query both roles and ACLs to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used id from previous solution, or uncomment and paste ID here\n",
    "# shared_endpoint_id = \"ID\"\n",
    "\n",
    "# Identity id of go@globusid.org. In practice, you would use the Globus Auth API to get the id of a\n",
    "# known identity username or email.\n",
    "go_identity_id = \"c699d42e-d274-11e5-bf75-1fc5bf53bb24\"\n",
    "role = {\n",
    "    \"DATA_TYPE\": \"role\",\n",
    "    \"principal_type\": \"identity\",\n",
    "    \"principal\": go_identity_id,\n",
    "    \"role\": \"access_manager\",\n",
    "}\n",
    "create_result = tc.add_endpoint_role(shared_endpoint_id, role)\n",
    "role_id = create_result[\"id\"]\n",
    "\n",
    "roles = tc.endpoint_role_list(shared_endpoint_id)\n",
    "print(\"Roles:\")\n",
    "for role in roles:\n",
    "    print(role[\"id\"], role[\"role\"], role[\"principal_type\"], role[\"principal\"])\n",
    "print()\n",
    "    \n",
    "acls = tc.endpoint_acl_list(shared_endpoint_id)\n",
    "print(\"ACLs:\")\n",
    "for acl in acls:\n",
    "    print(acl[\"id\"], acl[\"role_id\"], acl[\"principal_type\"], acl[\"principal\"], acl[\"permissions\"], acl[\"path\"])\n",
    "    \n",
    "# clean up role, so this cell can be re-run cleanly\n",
    "r = tc.delete_endpoint_role(shared_endpoint_id, role_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an ls given a bookmark name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookmark_name = \"My Tutorial Bookmark\"\n",
    "subpath = \"\" # must not start with slash\n",
    "\n",
    "# Get all bookmarks and see if one matches. A user can have at most 100 bookmarks, so this\n",
    "# is reasonable to do client side.\n",
    "endpoint_id = None\n",
    "bookmark_path = None\n",
    "for bmark in tc.bookmark_list():\n",
    "    if bmark[\"name\"] == bookmark_name:\n",
    "        endpoint_id = bmark[\"endpoint_id\"]\n",
    "        bookmark_path = bmark[\"path\"]\n",
    "        break\n",
    "        \n",
    "if endpoint_id is None:\n",
    "    print(\"Bookmark with name '{}' not found\".format(bookmark_name))\n",
    "else:\n",
    "    path = bookmark_path + subpath\n",
    "    print(\"path =\", path)\n",
    "    for item in tc.operation_ls(endpoint_id, path=path):\n",
    "        print(\"'{}' {} [{}]\".format(item[\"name\"], item[\"type\"], item[\"size\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a transfer akin to ‘rsync –av –delete’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_id = tutorial_endpoint_1\n",
    "dest_id = tutorial_endpoint_2\n",
    "tc.endpoint_autoactivate(source_id)\n",
    "tc.endpoint_autoactivate(dest_id)\n",
    "\n",
    "# This does not exactly match -a, for example it cannot preserve permissions or ownership.\n",
    "tdata = globus_sdk.TransferData(tc, source_id, dest_id,\n",
    "                                delete_destination_extra=True,\n",
    "                                preserve_timestamp=True)\n",
    "tdata.add_item(\"/share/godata/\", \"/~/gw16_notebook_godata/\", recursive=True)\n",
    "\n",
    "submit_result = tc.submit_transfer(tdata)\n",
    "\n",
    "# wait until transfer is complete, by polling every 15 seconds\n",
    "import time\n",
    "# Use the fields query parameter to get only the field we care about. This\n",
    "# decreases the size of the response, and is supported by most API resources.\n",
    "status = tc.get_task(submit_result[\"task_id\"], fields=\"status\")[\"status\"]\n",
    "poll_interval = 15 # in seconds\n",
    "max_wait = 360\n",
    "wait_time = 0\n",
    "while status not in (\"SUCCEEDED\", \"FAILED\") and wait_time < max_wait:\n",
    "    print(\"Task not yet complete (status {}), sleeping for {} seconds...\".format(\n",
    "            status, poll_interval))\n",
    "    time.sleep(poll_interval)\n",
    "    wait_time += poll_interval\n",
    "    status = tc.get_task(submit_result[\"task_id\"], fields=\"status\")[\"status\"]\n",
    "print(\"Task completed with status\", status)\n",
    "\n",
    "# The -v requires using the successful_transfers API, which happens to be missing from the REST documentation\n",
    "# as of day 1 at GW 16. It will be added shortly, in the Task Management section. It is almost identical to the\n",
    "# version available to endpoint administrators, described here (although still short on detail):\n",
    "#  https://docs.globus.org/api/transfer/advanced_endpoint_management/#get_task_successful_transfers_as_admin\n",
    "# It also doesn't yet have an SDK helper that automatically takes care of paging, so we do it manually here.\n",
    "if status == \"SUCCEEDED\":\n",
    "    next_marker=None\n",
    "    while True:\n",
    "        transfers = tc.get(\"/task/{}/successful_transfers\".format(submit_result[\"task_id\"], next_marker=next_marker))\n",
    "        next_marker = transfers[\"next_marker\"]\n",
    "        for t in transfers[\"DATA\"]:\n",
    "            print(t[\"source_path\"], \"->\", t[\"destination_path\"])\n",
    "        if next_marker is None:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer all files in a directory named `*.txt` to another endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_id = tutorial_endpoint_1\n",
    "dest_id = tutorial_endpoint_2\n",
    "tc.endpoint_autoactivate(source_id)\n",
    "tc.endpoint_autoactivate(dest_id)\n",
    "\n",
    "source_path = \"/share/godata/\"\n",
    "dest_path = \"/~/gw16_notebook_txt_godata/\"\n",
    "\n",
    "tdata = globus_sdk.TransferData(tc, source_id, dest_id)\n",
    "\n",
    "# Note that the filter happens on the REST server, not on the GridFTP endpoint. This means\n",
    "# that it still must request the entire directory contents from GridFTP. It reduces network\n",
    "# traffic between the REST client and server, but still may timeout for very large directories\n",
    "# because of REST service to GridFTP data stream size.\n",
    "for item in tc.operation_ls(source_id, path=source_path, filter=\"name:~*.txt\"):\n",
    "    tdata.add_item(source_path + item[\"name\"], dest_path + item[\"name\"])\n",
    "\n",
    "submit_result = tc.submit_transfer(tdata)\n",
    "print(\"Task ID:\", submit_result[\"task_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a transfer, monitor for completion, and monitor the event log. If a fault occurs, then cancel the job for some fault types (e.g., file not found), but not others (e.g., permission denied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_id = tutorial_endpoint_1\n",
    "dest_id = tutorial_endpoint_2\n",
    "tc.endpoint_autoactivate(source_id)\n",
    "tc.endpoint_autoactivate(dest_id)\n",
    "\n",
    "tdata = globus_sdk.TransferData(tc, source_id, dest_id)\n",
    "tdata.add_item(\"/share/godata/\", \"/~/gw16_notebook_godata/\", recursive=True)\n",
    "tdata.add_item(\"/share/godata/dne.txt\", \"/~/gw16_notebook_godata/dne.txt\")\n",
    "\n",
    "submit_result = tc.submit_transfer(tdata)\n",
    "\n",
    "cancel_on_errors = set([\"FILE_NOT_FOUND\"])\n",
    "\n",
    "# wait until transfer is complete, by polling every 15 seconds\n",
    "import time\n",
    "from datetime import datetime\n",
    "# Use the fields query parameter to get only the field we care about. This\n",
    "# decreases the size of the response, and is supported by most API resources.\n",
    "status = tc.get_task(submit_result[\"task_id\"], fields=\"status\")[\"status\"]\n",
    "poll_interval = 15 # in seconds\n",
    "max_wait = 360\n",
    "wait_time = 0\n",
    "last_error_dt = None\n",
    "cancel = False\n",
    "while status not in (\"SUCCEEDED\", \"FAILED\") and wait_time < max_wait and not cancel:\n",
    "    # Search the most recent errors for anything that we want to trigger a cancel,\n",
    "    # stopping if we get to an error we already saw in a previous iteration of the\n",
    "    # wait loop (the event list is sorted newest first).\n",
    "    for error in tc.task_event_list(submit_result[\"task_id\"], filter=\"is_error:1\"):\n",
    "        if error[\"code\"] in cancel_on_errors:\n",
    "            cancel = True\n",
    "            break\n",
    "        error_dt = datetime.strptime(error[\"time\"], \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "        if last_error_dt is not None and error_dt <= last_error_dt:\n",
    "            break\n",
    "        last_error_dt = error_dt\n",
    "    print(\"Task not yet complete (status {}), sleeping for {} seconds...\".format(\n",
    "          status, poll_interval))\n",
    "    time.sleep(poll_interval)\n",
    "    wait_time += poll_interval\n",
    "    status = tc.get_task(submit_result[\"task_id\"], fields=\"status\")[\"status\"]\n",
    "\n",
    "if cancel:\n",
    "    print(\"Encountered bad error, canceling task\")\n",
    "    tc.cancel_task(submit_result[\"task_id\"])\n",
    "elif status not in (\"SUCCEEDED\", \"FAILED\"):\n",
    "    print(\"Task did not complete before max wait time\")\n",
    "else:\n",
    "    print(\"Task completed with status\", status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
